---
sidebar_position: 4
title: 运行流程
date: 2020-12-27 23:57:49
"position": 4
---

# 前言
了解 Spark 应用程序的运行流程对于深入掌握 Spark 框架至关重要。它涉及到多个组件的协同工作，包括资源管理、任务调度和执行等关键环节。

# 基本概念
## 1. Application
本次运行的应用程序，是用户编写的 Spark 代码的整体体现，包含一系列操作和计算逻辑。

## 2. Driver
代表 `main()` 函数，负责创建 `SparkContext`。`SparkContext` 作为 Spark 应用程序的入口点，与 `ClusterManager` 通信，进行资源申请、任务分配和监控等操作。程序执行完毕后，关闭 `SparkContext`。

## 3. Executor
某个 `Application` 运行在 `Worker` 节点上的进程。负责运行具体的 `Task`，并将数据存储在内存或磁盘上。在 Spark On Yarn 模式下，进程名称为 `CoarseGrainedExecutorBackend`，其能运行 `Task` 的数量取决于分配的 CPU 个数。

## 4. Worker
集群中可运行 `Application` 的节点。在 Standalone 模式下，指通过 slave 文件配置的 worker 节点；在 Spark On Yarn 模式下，指 `NodeManager` 节点。

## 5. Task
在 `Executor` 进程中执行任务的基本工作单元，多个 `Task` 组成一个 `Stage`。每个 `Task` 负责处理一部分数据，完成特定计算任务。

## 6. Job
包含多个 `Task` 组成的并行计算，由行动算子（如 `collect`、`count` 等）触发。

## 7. Stage
每个 `Job` 会被拆分成多个组 `Task`，这些 `Task` 组成一个 `TaskSet`，即 `Stage`。`Stage` 的划分依据是 RDD 之间的依赖关系。

## 8. DAGScheduler
根据 `Job` 构建基于 `Stage` 的有向无环图（DAG），并将 `Stage` 提交给 `TaskScheduler`。通过分析 RDD 之间的依赖关系，确定任务执行顺序和划分 `Stage`。

## 9. TaskScheduler
将 `TaskSet` 提交给 `Worker`（集群）运行，负责分配每个 `Executor` 运行的 `Task`。

>注：
> 有关 `Application`、`Driver`、`Job`、`Stage`、`Task` 之间的关系如下图所示：
> （此处可插入相应的关系图）

# 运行流程
## 图解
（此处可插入 Spark 运行流程的详细图解）

## 文字说明
### 1. 构建运行环境
构建 `SparkApplication` 的运行环境，启动 `SparkContext`。`SparkContext` 向资源管理器（如 Standalone、Mesos 或者 Yarn）注册并申请运行 `Executor` 资源。

### 2. 资源分配与启动
资源管理器分配 `Executor` 资源并启动 `StandaloneExecutorBackend`。`Executor` 运行情况通过心跳发送到资源管理器，以便实时监控。

### 3. DAG 构建与任务申请
`SparkContext` 构建 DAG 图，将其分解成 `Stage`，并把 `TaskSet` 发送给 `Task Scheduler`。同时，`Executor` 向 `SparkContext` 申请 `Task`。

### 4. 任务发放与代码分发
`Task Scheduler` 将 `Task` 发放给 `Executor` 运行，`SparkContext` 将应用程序代码发放给 `Executor`，确保 `Executor` 能执行相应任务。

### 5. 任务执行与资源释放
`Task` 在 `Executor` 上运行，运行完毕后释放所有资源，完成整个作业的执行。